{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import data\n",
    "import transporter\n",
    "import torch.utils.data\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "image_channels = 3\n",
    "k = 4\n",
    "num_features = 32\n",
    "\n",
    "feature_encoder = transporter.FeatureEncoder(image_channels)\n",
    "pose_regressor = transporter.PoseRegressor(image_channels, k)\n",
    "refine_net = transporter.RefineNet(image_channels)\n",
    "\n",
    "model = transporter.Transporter(\n",
    "    feature_encoder, pose_regressor, refine_net\n",
    ")\n",
    "\n",
    "model.load_state_dict(\n",
    "    torch.load('checkpoints/model.pth', map_location='cpu')\n",
    ")\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Dataset, Sampler\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "dataset = Dataset('data', transform=transform)\n",
    "sampler = Sampler(dataset)\n",
    "loader = torch.utils.data.DataLoader(dataset,\n",
    "                                     batch_size=16,\n",
    "                                     sampler=sampler,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "for xt, xtp1 in loader:\n",
    "    break\n",
    "    \n",
    "target_keypoints = model.point_net(xtp1)\n",
    "reconstruction = model(xt, xtp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Circle\n",
    "from utils import get_n_colors\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(12, 4))\n",
    "idx = 6\n",
    "k_idx = 1\n",
    "std = 0.1\n",
    "\n",
    "\n",
    "feature_maps = transporter.spatial_softmax(target_keypoints)\n",
    "gmap = transporter.gaussian_map(feature_maps, std)[idx, k_idx]\n",
    "\n",
    "ax[0].imshow(xt[idx].permute([1, 2, 0]).detach().numpy(), cmap='gray')\n",
    "ax[1].imshow(xtp1[idx].permute([1, 2, 0]).detach().numpy())\n",
    "ax[2].imshow(reconstruction[idx].permute([1, 2, 0]).detach().numpy())\n",
    "ax[3].imshow(gmap.detach().numpy(), cmap='gray', vmin=0, vmax=1)\n",
    "ax[4].imshow(feature_maps[idx, k_idx].detach().numpy(), cmap='gray')\n",
    "\n",
    "locs = transporter.compute_keypoint_location_mean(\n",
    "    transporter.spatial_softmax(model.point_net(xtp1)))[idx]\n",
    "\n",
    "colors = get_n_colors(len(locs))\n",
    "for i, l in enumerate((locs + 1) / 2 * 80):\n",
    "    ax[1].add_patch(Circle((l[1].item(), l[0].item()), 2, \n",
    "                           color=colors[i], alpha=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def get_keypoints(model, source_images):\n",
    "    return transporter.compute_keypoint_location_mean(\n",
    "        transporter.spatial_softmax(model.point_net(source_images)))\n",
    "    return source_keypoints\n",
    "\n",
    "\n",
    "def annotate_keypoints(img, kp, colors):\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    for i, kp in enumerate(unnormalize_kp(kp_t, image_width)):\n",
    "        y = kp.detach().numpy()[0]\n",
    "        x = kp.detach().numpy()[1]\n",
    "        r = 2\n",
    "        draw.ellipse((x-r, y-r, x+r, y+r), tuple(colors[i]))\n",
    "    \n",
    "    return img\n",
    "\n",
    "def unnormalize_kp(kp, img_width):\n",
    "    return (kp + 1) / 2 * img_width\n",
    "\n",
    "traj = torch.stack(dataset.get_trajectory(0))\n",
    "keypoints = get_keypoints(model, traj)\n",
    "image_width = traj.size(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 3))\n",
    "\n",
    "colors = get_n_colors(k)\n",
    "colors = [(int(color[0] * 255), int(color[1]*255), int(color[2]*255), 255) for color in colors]\n",
    "for i, t in enumerate(range(0, 100, 20)):\n",
    "    frame_t = traj[t].permute([1, 2, 0])\n",
    "    kp_t = keypoints[t]\n",
    "    im = Image.fromarray((frame_t.detach().numpy() * 255).astype('uint8'))\n",
    "    annotate_keypoints(im, kp_t, colors)\n",
    "    im = np.array(im)\n",
    "    ax = fig.add_subplot(1, 5, i + 1)\n",
    "    ax.imshow(im)\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title('t = {}'.format(t))\n",
    "\n",
    "fig.savefig('assets/timesteps.pdf', bbox_inches='tight')\n",
    "fig.savefig('assets/timesteps.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "traj = torch.stack(dataset.get_trajectory(0))\n",
    "keypoints = get_keypoints(model, traj)\n",
    "image_width = traj.size(-1)\n",
    "\n",
    "def get_heatmaps(model, source_images, normalize=True):\n",
    "    if normalize:\n",
    "        return transporter.spatial_softmax(model.point_net(source_images))\n",
    "    return model.point_net(source_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, k+1, figsize=(12, 3))\n",
    "\n",
    "idx = 20\n",
    "\n",
    "ax[0].imshow(traj[idx].permute([1, 2, 0]).detach().numpy())\n",
    "ax[0].set_axis_off()\n",
    "\n",
    "hm = get_heatmaps(model, traj, normalize=False)[idx].detach().numpy()\n",
    "\n",
    "for i, m in enumerate(hm):\n",
    "    ax[i+1].imshow(m, cmap='gray')\n",
    "    ax[i+1].set_axis_off()\n",
    "    \n",
    "fig.savefig('assets/heatmaps_unnormalized.pdf', bbox_inches='tight')\n",
    "fig.savefig('assets/heatmaps_unnormalized.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, k+1, figsize=(12, 3))\n",
    "\n",
    "idx = 20\n",
    "\n",
    "ax[0].imshow(traj[idx].permute([1, 2, 0]).detach().numpy())\n",
    "ax[0].set_axis_off()\n",
    "\n",
    "\n",
    "hm = get_heatmaps(model, traj, normalize=True)[idx].detach().numpy()\n",
    "\n",
    "for i, m in enumerate(hm):\n",
    "    ax[i+1].imshow(m, cmap='gray')\n",
    "    ax[i+1].set_axis_off()\n",
    "fig.savefig('assets/heatmaps_normalized.pdf', bbox_inches='tight')\n",
    "fig.savefig('assets/heatmaps_normalized.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
